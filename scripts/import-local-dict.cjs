const fs = require('fs');
const path = require('path');
const { createClient } = require('@supabase/supabase-js');

// Helper to parse .env file
function parseEnv() {
    try {
        const envPath = path.resolve(__dirname, '../.env');
        if (!fs.existsSync(envPath)) return {};
        const content = fs.readFileSync(envPath, 'utf-8');
        const env = {};
        content.split('\n').forEach(line => {
            const parts = line.split('=');
            if (parts.length >= 2) {
                const key = parts[0].trim();
                const val = parts.slice(1).join('=').trim().replace(/^["']|["']$/g, '');
                env[key] = val;
            }
        });
        return env;
    } catch (e) {
        console.error("Error reading .env", e);
        return {};
    }
}

const env = parseEnv();
const SUPABASE_URL = env.VITE_SUPABASE_URL || 'http://127.0.0.1:54321';
const SUPABASE_KEY = env.VITE_SUPABASE_ANON_KEY || env.VITE_SUPABASE_PUBLISHABLE_KEY;

if (!SUPABASE_KEY) {
    console.error("Missing Supabase Key");
    process.exit(1);
}

console.log(`Connecting to Supabase at ${SUPABASE_URL}`);
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

const DICT_DIR = '/Volumes/aikaifa/claudekaifa/fuke/ai-english-club/json-full';

async function importDict() {
    if (!fs.existsSync(DICT_DIR)) {
        console.error(`Dictionary directory not found: ${DICT_DIR}`);
        return;
    }

    const files = fs.readdirSync(DICT_DIR).filter(f => f.endsWith('.json'));
    console.log(`Found ${files.length} dictionary files.`);

    let totalImported = 0;

    for (const file of files) {
        console.log(`Processing ${file}...`);
        try {
            const content = fs.readFileSync(path.join(DICT_DIR, file), 'utf-8');
            // Some files might be huge, check size? Assuming manageable.
            const json = JSON.parse(content);

            const inputs = [];

            for (const item of json) {
                if (!item.content || !item.content.word) continue;

                const wordData = item.content.word;
                const headWord = wordData.wordHead;
                if (!headWord) continue;

                // Phonetic
                // Priority: usphone -> ukphone -> phone
                const phonetic = wordData.content.usphone ||
                    wordData.content.ukphone ||
                    wordData.content.phone || '';

                // Translation (Summary)
                const trans = wordData.content.trans || [];
                const translation = trans.map(t => {
                    // Format: n. meaning; adj. meaning
                    // Just use translation text (tranCn)
                    return `${t.pos ? t.pos + '. ' : ''}${t.tranCn}`;
                }).slice(0, 1).join('; '); // Use first definition as summary translation

                // Definitions (Detailed)
                const definitions = trans.map(t => ({
                    partOfSpeech: t.pos || '',
                    definition: t.tranCn || t.tranOther || ''
                }));

                inputs.push({
                    word: headWord.toLowerCase(),
                    phonetic: phonetic ? `/${phonetic}/` : '', // Add slashes if missing? Typically raw is stored.
                    translation: translation,
                    definitions: definitions,
                    // cachedAt: generated by db or ignored if schema defaults? 
                    // Note: word_cache usually relies on client usage, but here we preload.
                });
            }

            if (inputs.length === 0) continue;

            // Upsert in chunks
            const CHUNK_SIZE = 100;
            for (let i = 0; i < inputs.length; i += CHUNK_SIZE) {
                const chunk = inputs.slice(i, i + CHUNK_SIZE);
                const { error } = await supabase.from('word_cache').upsert(chunk, { onConflict: 'word' });

                if (error) {
                    console.error(`Error upserting chunk in ${file}:`, error.message);
                } else {
                    totalImported += chunk.length;
                }
            }
            console.log(`Imported ${inputs.length} words from ${file}`);

        } catch (err) {
            console.error(`Failed to process ${file}:`, err.message);
        }
    }

    console.log(`Import completed. Total words upserted: ${totalImported}`);
}

importDict();
